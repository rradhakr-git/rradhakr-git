{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy & Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='steelblue'>\n",
    "\n",
    "<span style=\"font-family:verdana; font-size:1.4em;\">\n",
    "\n",
    "<b>Using Spacy to prepare the text do sentiment analysis, use a classifier to train the model and make prediction<br></b>\n",
    "<ul>\n",
    "    <li>Data is from University of California Irvine</li>\n",
    "    <li>Data consists of messages received on Yelp, IMDB and Amazon,It contains sentences labelled with positive or negative sentiment, extracted from reviews of products, movies, and restaurants</li>\n",
    "    <li>For each website, there exist 500 positive and 500 negative sentences. Those were selected randomly for larger datasets of reviews</li> \n",
    "    <li>We attempted to select sentences that have a clearly positive or negative connotaton, the goal was for no neutral sentences to be selected</li>\n",
    "</ul>\n",
    "\n",
    "</span>\n",
    "\n",
    "</font>\n",
    "<br><br>\n",
    "<font color='grey'>\n",
    "<span style=\"font-family:verdana; font-size:1.2em;\">\n",
    "    <b>Code includes:\n",
    "    <ul>\n",
    "        <li>Loading the datasets</li>\n",
    "        <li>Processing the messages using Spacy</li>\n",
    "        <li>Build pipeline to perform preprocessing and training model</li>\n",
    "        <li>Train model</li>\n",
    "        <li>Evaluate model</li>\n",
    "     </ul>\n",
    "    </b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install spacy<br>\n",
    "<font color='tomato'>\n",
    "<span style=\"font-family:verdana; font-size:1.4em;\">\n",
    "    Couple of options to install spacy:\n",
    "    <ul>\n",
    "        <li>conda install -c conda-forge spacy</li>\n",
    "        <li>pip install spacy</li>\n",
    "    </ul><br>\n",
    "    In anaconda terminal use the following commands to download small model or large model:\n",
    "    <ul>\n",
    "        <li>python -m spacy download en_core_web_sm</li>\n",
    "        <li>python -m spacy download en_core_web_lg</li>\n",
    "    </ul>\n",
    "        \n",
    "</span>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets<br>\n",
    "<font color='gray'>\n",
    "\n",
    "<span style=\"font-family:verdana; font-size:1.2em;\">\n",
    "    <ul>\n",
    "        <li>There are three different text files with the message and sentiment separated by tab</li>\n",
    "        <li>These files are from Yelp, IMDB and Amazon</li>\n",
    "        <li>For each website there are 500 positive and 500 negative reviews (selected from larger datasets)</li>\n",
    "    </ul>\n",
    "</span>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfYelp = pd.read_table('../datasets/yelp_labelled.txt')\n",
    "dfImdb = pd.read_table('../datasets/imdb_labelled.txt')\n",
    "dfAmz = pd.read_table('../datasets/amazon_cells_labelled.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the tables\n",
    "tables = [dfYelp, dfImdb, dfAmz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column header\n",
    "for colname in tables:\n",
    "    colname.columns = ['Message', 'Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname in tables:\n",
    "    print(colname.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a Key to Make it Easier\n",
    "keys = ['Yelp','IMDB','Amazon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe by merging the tables\n",
    "df = pd.concat(tables, keys = keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Text using spaCy<br>\n",
    "<font color='gray'>\n",
    "<span style=\"font-family:verdana; font-size:1.2em;\">\n",
    "    Do following processing:<br>\n",
    "    <ul>\n",
    "        <li>Remove stop words, punctuations</li>\n",
    "        <li>Convert the text to lower case and strip leading and trailing spaces</li>\n",
    "        <li>Tokenize the words</li>\n",
    "    </ul>\n",
    "</span>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text processing libraries\n",
    "from spacy.lang.en.stop_words import STOP_WORDS          # stop words\n",
    "import string                                            # for punctuations\n",
    "from spacy.lang.en import English                        # english parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "parser = English()\n",
    "stopwords = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tokenizer using Spacy\n",
    "def spacyTokenizer(sentence):\n",
    "    tokens = parser(sentence)\n",
    "    tokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens]\n",
    "    tokens = [word for word in tokens if word not in stopwords and word not in punctuations]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the text of leading and trailing spaces & convert it to lower case\n",
    "def cleanText(text):\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom transformer using Spacy\n",
    "\n",
    "class Predictors(TransformerMixin):\n",
    "    \n",
    "    def transform(self, data, **transform_params):\n",
    "        return [cleanText(text) for text in data]\n",
    "    \n",
    "    def fit(self, data, y = None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Pipeline<br>\n",
    "<font color='gray'>\n",
    "\n",
    "\n",
    "<span style=\"font-family:verdana; font-size:1.2em;\">\n",
    "    Build a pipeline to do the following:\n",
    "    <ul>\n",
    "        <li>Preprocess the text (using functions defined above)</li>\n",
    "        <li>Tokenize the text</li>\n",
    "        <li>Apply classifier to perform training</li>\n",
    "    </ul>\n",
    "</span>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Click following link for more info on TF-IDF\n",
    "<a href=\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\" target=\"_blank\">TF-IDF</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorizer\n",
    "tfvectorizer = TfidfVectorizer(tokenizer = spacyTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "classifier = LogisticRegression(verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Message']\n",
    "y = df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "pipe = Pipeline([(\"cleaner\", Predictors()),\n",
    "                (\"vectorizer\", tfvectorizer),\n",
    "                (\"classifier\", classifier)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance<br>\n",
    "<font color='gray'>\n",
    "\n",
    "<span style=\"font-family:verdana; font-size:1.2em;\">\n",
    "    Evaluate the model performance with following:\n",
    "    <ul>\n",
    "        <li>Print accuracy of the training and predictions</li>\n",
    "        <li>Print classification report</li>\n",
    "        <li>Confusion Matrix</li>\n",
    "    </ul>\n",
    "</span>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print 10 predictions\n",
    "i = 0\n",
    "for (sample, pred) in zip(X_test, predictions):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(sample, 'Prediction --> ', pred)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model accuracy\n",
    "print(\"Train Accuracy: \", pipe.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy: \",pipe.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cseg = [\"Negative\", \"Positive\"]\n",
    "cm_df = pd.DataFrame(cm, index = cseg, columns = cseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.figure(figsize = (10, 6))\n",
    "sns.heatmap(cm_df, annot=True, cmap=plt.cm.Blues, fmt = 'g', annot_kws={\"size\": 16})\n",
    "sns.set(font_scale=0.5)\n",
    "plt.title('Confusion Matrix\\n', fontsize = 18)\n",
    "plt.ylabel('True label', fontsize = 16)\n",
    "plt.xlabel('Predicted label', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\"It was a great movie\",\n",
    "            \"I do enjoy my job\",\n",
    "            \"What a poor product!,I will have to get a new one\",\n",
    "            \"It was amazing feeling!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.predict(examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
