{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adoption Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='steelblue'>\n",
    "\n",
    "<span style=\"font-family:verdana; font-size:1.6em;\">\n",
    "    <b>PetFinder Prediction</b><br>\n",
    "    Petfinder dataset is about predicting how fast a pet is adopted based on pet's listing on PetFinder. <br>\n",
    "    Classify if the pet will be adopted or not<br><br>\n",
    "</span>\n",
    "<span style=\"font-family:verdana; font-size:1.4em;\">\n",
    "    <b>Following examples are included in the processing:</b><em>\n",
    "    <ol>\n",
    "        <li>Load training and test data including labels</li>\n",
    "        <li>Handle the categorical values using a pipeline</li>\n",
    "        <li>Create a Neural Network and build a model</li>\n",
    "        <li>Train the model on the training dataset</li>\n",
    "        <li>Evaluate the accuracy of the model using test dataset</li>\n",
    "        <li>Plot the accuracy and loss for the model</li>\n",
    "    </ol></em>    \n",
    "</span>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='steelblue'>\n",
    "\n",
    "<span style=\"font-family:verdana; font-size:1.6em;\">\n",
    "    To install pydot (in anaconda terminal):\n",
    "    <ul>\n",
    "        <li>pip install pydot</li><br>\n",
    "        OR  <br><br>\n",
    "        <li>conda install -c conda-forge pydot</li>\n",
    "    </ul>\n",
    "</span>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fields\n",
    "- PetID - Unique hash ID of pet profile\n",
    "- AdoptionSpeed - Categorical speed of adoption. Lower is faster. This is the value to predict. See below section for more info.\n",
    "- Type - Type of animal (1 = Dog, 2 = Cat)\n",
    "- Name - Name of pet (Empty if not named)\n",
    "- Age - Age of pet when listed, in months\n",
    "- Breed1 - Primary breed of pet (Refer to BreedLabels dictionary)\n",
    "- Breed2 - Secondary breed of pet, if pet is of mixed breed (Refer to BreedLabels dictionary)\n",
    "- Gender - Gender of pet (1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets)\n",
    "- Color1 - Color 1 of pet (Refer to ColorLabels dictionary)\n",
    "- Color2 - Color 2 of pet (Refer to ColorLabels dictionary)\n",
    "- Color3 - Color 3 of pet (Refer to ColorLabels dictionary)\n",
    "- MaturitySize - Size at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)\n",
    "- FurLength - Fur length (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)\n",
    "- Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "- Dewormed - Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "- Sterilized - Pet has been spayed / neutered (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "- Health - Health Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified)\n",
    "- Quantity - Number of pets represented in profile\n",
    "- Fee - Adoption fee (0 = Free)\n",
    "- State - State location in Malaysia (Refer to StateLabels dictionary)\n",
    "- RescuerID - Unique hash ID of rescuer\n",
    "- VideoAmt - Total uploaded videos for this pet\n",
    "- PhotoAmt - Total uploaded photos for this pet\n",
    "- Description - Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdoptionSpeed\n",
    "\n",
    "Contestants are required to predict this value. The value is determined by how quickly, if at all, a pet is adopted. The values are determined in the following way:<br>\n",
    "0 - Pet was adopted on the same day as it was listed.<br>\n",
    "1 - Pet was adopted between 1 and 7 days (1st week) after being listed.<br>\n",
    "2 - Pet was adopted between 8 and 30 days (1st month) after being listed.<br>\n",
    "3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed.<br>\n",
    "4 - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days).<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import json\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the datasets (train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('../datasets/pet-train.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['Type'] = traindf['Type'].map({1: 'Dog', 2: 'Cat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the test dataset to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf = pd.read_csv('../datasets/pet-test.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf['Type'] = evaldf['Type'].map({1: 'Dog', 2: 'Cat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create target variable<br>\n",
    "<font color='gray'>\n",
    "\n",
    "<span style=\"font-family:verdana; font-size:1.2em;\">\n",
    "    <ul> \n",
    "<li>Let's simplify this for our tutorial. Here, you will transform this into a binary classification problem, and simply predict whether the pet was adopted, or not</li>\n",
    "<li>After modifying the label column, 0 will indicate the pet was not adopted, and 1 will indicate it was</li>\n",
    "    </ul>\n",
    "</span>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['AdoptionSpeed'].value_counts().sort_index().plot(kind = 'barh', \n",
    "                                                          color='steelblue')\n",
    "plt.xlabel('count')\n",
    "plt.ylabel('days')\n",
    "plt.title('Adoption speed classes counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4));\n",
    "sns.countplot(x='Type', data = traindf);\n",
    "plt.title('Number of cats and dogs in train data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop = ['Name', 'RescuerID', 'PetID', 'AdoptionSpeed', 'Description' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the original dataset \"4\" indicates the pet was not adopted.\n",
    "traindf['target'] = np.where(traindf['AdoptionSpeed'] == 4, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.drop(columns = todrop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdoptionSpeed features does not exist in the test data \n",
    "todrop.remove('AdoptionSpeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetCol = traindf.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf.drop(columns = todrop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf.head().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Cateogorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
    "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
    "       'Sterilized', 'Health', 'State', 'Health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for these categorical columns, convert the numbers to strings\n",
    "# These are ordinal values i.e. the numbers have mathematical meaning\n",
    "for col in cat_cols:\n",
    "    traindf[col] = traindf[col].astype(str)\n",
    "    evaldf[col] = evaldf[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline stages for numeric and categorical columns\n",
    "numericPipe = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),\n",
    "                              ('scaler', StandardScaler())])\n",
    "stringPipe = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', \n",
    "                                                       fill_value='missing')),\n",
    "                             ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of numeric and categorical columns\n",
    "numericCols = traindf.select_dtypes(include=['int64', 'float64']).columns\n",
    "stringCols = traindf.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numericPipe, numericCols),\n",
    "                                               ('cat', stringPipe, stringCols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = preprocessor.fit_transform(traindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# look at first row in the sparse matrix\n",
    "tlist = []\n",
    "count = 0\n",
    "for i in df1:\n",
    "    tlist.append(list(i.A[0]))\n",
    "    count += 1\n",
    "    if (count >= 1):\n",
    "        break\n",
    "print(tlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf1 = preprocessor.transform(evaldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = targetCol.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1, y, test_size = 0.25, \n",
    "                                                    random_state = 2345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rankdir='LR' is used to make the graph horizontal.\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sparse matrix to numpy array so that validation split can \n",
    "# be applied when training is applied\n",
    "X_train = X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCHES = 128\n",
    "history = model.fit(X_train, y_train, batch_size = BATCHES, validation_split = 0.20,\n",
    "                    epochs = EPOCHS, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = model.metrics_names\n",
    "metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.title('Training and validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in metrics_names:\n",
    "    plot_graphs(history, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let us evaluate with the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(evaldf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.astype(int)\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf['target'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf.loc[evaldf['target'] == 1, 'target'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf.loc[evaldf['target'] == 0, 'target'].count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
